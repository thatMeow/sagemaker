{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import boto3\n",
    "import io\n",
    "import sagemaker\n",
    "# from sagemaker import Session\n",
    "# from sagemaker import estimator\n",
    "from sagemaker.amazon.common import write_numpy_to_dense_tensor\n",
    "import sagemaker.amazon.common as smac\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "import pickle, gzip, numpy, urllib.request, json\n",
    "\n",
    "import psycopg2\n",
    "import getpass\n",
    "import sys\n",
    "from os.path import expanduser\n",
    "import os\n",
    "import re\n",
    "\n",
    "import boto3\n",
    "\n",
    "import subprocess # Use subprocess to execute aws command line\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "#sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from functools import reduce\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# ROC Curve with logistic regression\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "from plotly import tools\n",
    "\n",
    "# Make plotly work with Jupyter notebook\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import Markdown as md\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# hide warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "sagemaker = boto3.client('sagemaker')\n",
    "runtime = boto3.client('runtime.sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for markdown print\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes to be used in pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFFunctionTransformer(TransformerMixin, BaseEstimator):\n",
    "    # FunctionTransformer but for pandas DataFrames\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.ft = FunctionTransformer(*args, **kwargs)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # stateless transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        Xt = self.ft.transform(X)\n",
    "        Xt = pd.DataFrame(Xt, index=X.index, columns=X.columns)\n",
    "        return Xt\n",
    "\n",
    "\n",
    "class DFFeatureUnion(TransformerMixin, BaseEstimator):\n",
    "    # FeatureUnion but for pandas DataFrames\n",
    "\n",
    "    def __init__(self, transformer_list):\n",
    "        self.transformer_list = transformer_list\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for (name, t) in self.transformer_list:\n",
    "            t.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xts = [t.transform(X) for _, t in self.transformer_list]\n",
    "        Xunion = reduce(lambda X1, X2: pd.merge(X1, X2, left_index=True, right_index=True), Xts)\n",
    "        return Xunion\n",
    "\n",
    "\n",
    "class DFImputer(TransformerMixin, BaseEstimator):\n",
    "    # Imputer but for pandas DataFrames\n",
    "\n",
    "    def __init__(self, strategy='mean'):\n",
    "        self.strategy = strategy\n",
    "        self.imp = None\n",
    "        self.statistics_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.imp = Imputer(strategy=self.strategy)\n",
    "        self.imp.fit(X)\n",
    "        self.statistics_ = pd.Series(self.imp.statistics_, index=X.columns)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Ximp = self.imp.transform(X)\n",
    "        Xfilled = pd.DataFrame(Ximp, index=X.index, columns=X.columns)\n",
    "        return Xfilled\n",
    "\n",
    "\n",
    "class DFStandardScaler(TransformerMixin, BaseEstimator):\n",
    "    # StandardScaler but for pandas DataFrames\n",
    "\n",
    "    def __init__(self):\n",
    "        self.ss = None\n",
    "        self.mean_ = None\n",
    "        self.scale_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.ss = StandardScaler()\n",
    "        self.ss.fit(X)\n",
    "        self.mean_ = pd.Series(self.ss.mean_, index=X.columns)\n",
    "        self.scale_ = pd.Series(self.ss.scale_, index=X.columns)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xss = self.ss.transform(X)\n",
    "        Xscaled = pd.DataFrame(Xss, index=X.index, columns=X.columns)\n",
    "        return Xscaled\n",
    "\n",
    "\n",
    "class DFRobustScaler(TransformerMixin, BaseEstimator):\n",
    "    # RobustScaler but for pandas DataFrames\n",
    "\n",
    "    def __init__(self):\n",
    "        self.rs = None\n",
    "        self.center_ = None\n",
    "        self.scale_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.rs = RobustScaler()\n",
    "        self.rs.fit(X)\n",
    "        self.center_ = pd.Series(self.rs.center_, index=X.columns)\n",
    "        self.scale_ = pd.Series(self.rs.scale_, index=X.columns)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xrs = self.rs.transform(X)\n",
    "        Xscaled = pd.DataFrame(Xrs, index=X.index, columns=X.columns)\n",
    "        return Xscaled\n",
    "\n",
    "\n",
    "class ColumnExtractor(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # stateless transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xcols = X[self.cols]\n",
    "        return Xcols\n",
    "\n",
    "\n",
    "class ZeroFillTransformer(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # stateless transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xz = X.fillna(value=0)\n",
    "        return Xz\n",
    "\n",
    "\n",
    "class Log1pTransformer(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # stateless transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xlog = np.log1p(X)\n",
    "        return Xlog\n",
    "\n",
    "\n",
    "class DateFormatter(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # stateless transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xdate = X.apply(pd.to_datetime)\n",
    "        return Xdate\n",
    "\n",
    "\n",
    "class DateDiffer(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # stateless transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        beg_cols = X.columns[:-1]\n",
    "        end_cols = X.columns[1:]\n",
    "        Xbeg = X[beg_cols].as_matrix()\n",
    "        Xend = X[end_cols].as_matrix()\n",
    "        Xd = (Xend - Xbeg) / np.timedelta64(1, 'D')\n",
    "        diff_cols = ['->'.join(pair) for pair in zip(beg_cols, end_cols)]\n",
    "        Xdiff = pd.DataFrame(Xd, index=X.index, columns=diff_cols)\n",
    "        return Xdiff\n",
    "\n",
    "\n",
    "class DummyTransformer(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.dv = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # assumes all columns of X are strings\n",
    "        Xdict = X.to_dict('records')\n",
    "        self.dv = DictVectorizer(sparse=False)\n",
    "        self.dv.fit(Xdict)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xdict = X.to_dict('records')\n",
    "        Xt = self.dv.transform(Xdict)\n",
    "        cols = self.dv.get_feature_names()\n",
    "        Xdum = pd.DataFrame(Xt, index=X.index, columns=cols)\n",
    "        # drop column indicating NaNs\n",
    "        nan_cols = [c for c in cols if '=' not in c]\n",
    "        Xdum = Xdum.drop(nan_cols, axis=1)\n",
    "        return Xdum\n",
    "\n",
    "\n",
    "class MultiEncoder(TransformerMixin, BaseEstimator):\n",
    "    # Multiple-column MultiLabelBinarizer for pandas DataFrames\n",
    "\n",
    "    def __init__(self, sep=','):\n",
    "        self.sep = sep\n",
    "        self.mlbs = None\n",
    "\n",
    "    def _col_transform(self, x, mlb):\n",
    "        cols = [''.join([x.name, '=', c]) for c in mlb.classes_]\n",
    "        xmlb = mlb.transform(x)\n",
    "        xdf = pd.DataFrame(xmlb, index=x.index, columns=cols)\n",
    "        return xdf\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        Xsplit = X.applymap(lambda x: x.split(self.sep))\n",
    "        self.mlbs = [MultiLabelBinarizer().fit(Xsplit[c]) for c in X.columns]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xsplit = X.applymap(lambda x: x.split(self.sep))\n",
    "        Xmlbs = [self._col_transform(Xsplit[c], self.mlbs[i])\n",
    "                 for i, c in enumerate(X.columns)]\n",
    "        Xunion = reduce(lambda X1, X2: pd.merge(X1, X2, left_index=True, right_index=True), Xmlbs)\n",
    "        return Xunion\n",
    "\n",
    "\n",
    "class StringTransformer(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # stateless transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xstr = X.applymap(str)\n",
    "        return Xstr\n",
    "\n",
    "\n",
    "class ClipTransformer(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def __init__(self, a_min, a_max):\n",
    "        self.a_min = a_min\n",
    "        self.a_max = a_max\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # stateless transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xclip = np.clip(X, self.a_min, self.a_max)\n",
    "        return Xclip\n",
    "\n",
    "\n",
    "class AddConstantTransformer(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def __init__(self, c=1):\n",
    "        self.c = c\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # stateless transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xc = X + self.c\n",
    "        return Xc\n",
    "\n",
    "\n",
    "class MultiColumnLabelEncoder(TransformerMixin, BaseEstimator):  \n",
    "    \"\"\"Transformer for applying label encoder on multiple columns.\n",
    "\n",
    "    This transformer applies label encoding to columns in a dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.d = defaultdict(LabelEncoder)\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        \"\"\"Transforms X to have columns label encoded.\n",
    "\n",
    "        Args:\n",
    "            X (obj): The dataset to transform. Can be dataframe or matrix.\n",
    "            transform_params (kwargs, optional): Additional params.\n",
    "\n",
    "        Returns:\n",
    "            The transformed dataset with the label encoded columns.\n",
    "        \"\"\"\n",
    "        X = X.fillna('NaN')  # fill null values with 'NaN'\n",
    "        transformed = X.apply(lambda x: self.d[x.name].transform(x))\n",
    "        return transformed\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        \"\"\"Fits transfomer over X.\n",
    "\n",
    "        Needs to apply fit over the defaultdict so as to retain the\n",
    "        label classes when transforming.\n",
    "        \"\"\"\n",
    "        X = X.fillna('NaN')  # fill null values with 'NaN'\n",
    "        X.apply(lambda x: self.d[x.name].fit(x))\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'jornaya-ds-us-east-1-sagemaker'\n",
    "train_key = 'amiao/sagemaker_poc/lincoln_tech/raw_data/lincoln_tech_enroll_train_60.csv'\n",
    "train_data = s3.get_object(Bucket = bucket, Key = train_key)\n",
    "\n",
    "val_key = 'amiao/sagemaker_poc/lincoln_tech/raw_data/lincoln_tech_enroll_val_40.csv'\n",
    "val_data = s3.get_object(Bucket = bucket, Key = val_key)\n",
    "\n",
    "train = pd.read_csv(io.BytesIO(train_data['Body'].read()))\n",
    "val = pd.read_csv(io.BytesIO(val_data['Body'].read()))\n",
    "full = train.append(val)\n",
    "\n",
    "# Let's drop 'token' for now since it will not be used in our modeling process\n",
    "full_orig = full.copy()\n",
    "full = full.drop('token', axis=1)\n",
    "full = full.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('lincoln_tech_predict_score', axis=1)\n",
    "y = train['lincoln_tech_predict_score'].values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.4 , shuffle=False) #\n",
    "# full_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "# numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTCOME = 'lincoln_tech_predict_score'\n",
    "# NEAR_UNIQUE_FEATS = ['name_of_event', 'year_month_app', 'organization']\n",
    "# DATE_FEATS = ['application_date', 'event_start_date', 'event_end_date']\n",
    "\n",
    "DUMMY_FEATS = [':degree_level_sought']\n",
    "\n",
    "LABELENCODER_FEATS = ['mobile_device_type_hashed'\n",
    "                      , 'DeviceType'\n",
    "                      , 'absent_start', 'call_center', 'has_email', 'has_phone', 'is_mobile_device']#'Browser', 'Platform', , 'url_domain', 'geoip_postal_code', ':high_school_graduation_year'\n",
    "\n",
    "NUM_FEATS = [ \n",
    " 'consumer_five_minutes',\n",
    " 'consumer_hour',\n",
    " 'consumer_twelve_hours',\n",
    " 'consumer_day',\n",
    " 'consumer_week',\n",
    " 'device_five_minutes',\n",
    " 'device_hour',\n",
    " 'device_twelve_hours',\n",
    " 'device_day',\n",
    " 'device_week',\n",
    " 'fields_changed',\n",
    " 'fields_interacted',\n",
    " 'ip_five_minutes',\n",
    " 'ip_hour',\n",
    " 'ip_twelve_hours',\n",
    " 'ip_day',\n",
    " 'ip_week',\n",
    " 'lead_age',\n",
    " 'lead_duration',\n",
    " 'pct_field_changes',\n",
    " 'pct_field_interactions',\n",
    " 'pct_fields_changed',\n",
    " 'pct_fields_interacted',\n",
    " 'total_entities',\n",
    " 'device_count_30_days',\n",
    " 'device_count_60_days',\n",
    " 'email_count_30_days',\n",
    " 'email_count_60_days',\n",
    " 'lead_five_minutes',\n",
    " 'lead_hour',\n",
    " 'lead_twelve_hours',\n",
    " 'lead_day',\n",
    " 'lead_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing with a Pipeline\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('features', DFFeatureUnion([\n",
    "#         ('dates', Pipeline([\n",
    "#             ('extract', ColumnExtractor(DATE_FEATS)),\n",
    "#             ('to_date', DateFormatter()),\n",
    "#             ('diffs', DateDiffer()),\n",
    "#             ('mid_fill', DFImputer(strategy='median'))\n",
    "#         ])),\n",
    "        ('categoricals', Pipeline([\n",
    "            ('extract', ColumnExtractor(DUMMY_FEATS)),\n",
    "            ('dummy', DummyTransformer())\n",
    "        ])),\n",
    "        ('multi_labels', Pipeline([\n",
    "            ('extract', ColumnExtractor(LABELENCODER_FEATS)),\n",
    "            ('transform_to_string', StringTransformer()),\n",
    "            ('labencode', MultiColumnLabelEncoder()),\n",
    "        ])),\n",
    "        ('numerics', Pipeline([\n",
    "            ('extract', ColumnExtractor(NUM_FEATS)),\n",
    "            ('fill_with_mean', DFImputer(strategy='mean'))\n",
    "#             ('log', Log1pTransformer())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('scale', DFStandardScaler())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = preprocessing_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribute variables into four categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing with a Pipeline\n",
    "lr_pipeline = Pipeline([\n",
    "    ('features', DFFeatureUnion([\n",
    "#         ('dates', Pipeline([\n",
    "#             ('extract', ColumnExtractor(DATE_FEATS)),\n",
    "#             ('to_date', DateFormatter()),\n",
    "#             ('diffs', DateDiffer()),\n",
    "#             ('mid_fill', DFImputer(strategy='median'))\n",
    "#         ])),\n",
    "        ('categoricals', Pipeline([\n",
    "            ('extract', ColumnExtractor(DUMMY_FEATS)),\n",
    "            ('dummy', DummyTransformer())\n",
    "        ])),\n",
    "        ('multi_labels', Pipeline([\n",
    "            ('extract', ColumnExtractor(LABELENCODER_FEATS)),\n",
    "            ('transform_to_string', StringTransformer()),\n",
    "            ('labencode', MultiColumnLabelEncoder()),\n",
    "        ])),\n",
    "        ('numerics', Pipeline([\n",
    "            ('extract', ColumnExtractor(NUM_FEATS)),\n",
    "            ('fill_with_mean', DFImputer(strategy='mean'))\n",
    "#             ('log', Log1pTransformer())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('scale', DFStandardScaler()),\n",
    "    ('lr_clf', LogisticRegression())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', DFFeatureUnion(transformer_list=[('categoricals', Pipeline(memory=None,\n",
       "     steps=[('extract', ColumnExtractor(cols=[':degree_level_sought'])), ('dummy', DummyTransformer())])), ('multi_labels', Pipeline(memory=None,\n",
       "     steps=[('extract', ColumnExtractor(cols=['mobile_device_t...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_pipeline.predict_proba(X_val)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5858486102626055"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr_val, tpr_val, thresholds_val = roc_curve(y_val, y_pred)\n",
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline with AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing with a Pipeline\n",
    "ab_pipeline = Pipeline([\n",
    "    ('features', DFFeatureUnion([\n",
    "#         ('dates', Pipeline([\n",
    "#             ('extract', ColumnExtractor(DATE_FEATS)),\n",
    "#             ('to_date', DateFormatter()),\n",
    "#             ('diffs', DateDiffer()),\n",
    "#             ('mid_fill', DFImputer(strategy='median'))\n",
    "#         ])),\n",
    "        ('categoricals', Pipeline([\n",
    "            ('extract', ColumnExtractor(DUMMY_FEATS)),\n",
    "            ('dummy', DummyTransformer())\n",
    "        ])),\n",
    "        ('multi_labels', Pipeline([\n",
    "            ('extract', ColumnExtractor(LABELENCODER_FEATS)),\n",
    "            ('transform_to_string', StringTransformer()),\n",
    "            ('labencode', MultiColumnLabelEncoder()),\n",
    "        ])),\n",
    "        ('numerics', Pipeline([\n",
    "            ('extract', ColumnExtractor(NUM_FEATS)),\n",
    "            ('fill_with_mean', DFImputer(strategy='mean'))\n",
    "#             ('log', Log1pTransformer())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('scale', DFStandardScaler()),\n",
    "    ('adaboost', AdaBoostClassifier(n_estimators=50,\n",
    "                         learning_rate=0.2,\n",
    "                         random_state=0))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', DFFeatureUnion(transformer_list=[('categoricals', Pipeline(memory=None,\n",
       "     steps=[('extract', ColumnExtractor(cols=[':degree_level_sought'])), ('dummy', DummyTransformer())])), ('multi_labels', Pipeline(memory=None,\n",
       "     steps=[('extract', ColumnExtractor(cols=['mobile_device_t...ithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=0.2, n_estimators=50, random_state=0))])"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ab_pipeline.predict_proba(X_val)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6028906145277991"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr_val, tpr_val, thresholds_val = roc_curve(y_val, y_pred)\n",
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline with Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing with a Pipeline\n",
    "gb_pipeline = Pipeline([\n",
    "    ('features', DFFeatureUnion([\n",
    "#         ('dates', Pipeline([\n",
    "#             ('extract', ColumnExtractor(DATE_FEATS)),\n",
    "#             ('to_date', DateFormatter()),\n",
    "#             ('diffs', DateDiffer()),\n",
    "#             ('mid_fill', DFImputer(strategy='median'))\n",
    "#         ])),\n",
    "        ('categoricals', Pipeline([\n",
    "            ('extract', ColumnExtractor(DUMMY_FEATS)),\n",
    "            ('dummy', DummyTransformer())\n",
    "        ])),\n",
    "        ('multi_labels', Pipeline([\n",
    "            ('extract', ColumnExtractor(LABELENCODER_FEATS)),\n",
    "            ('transform_to_string', StringTransformer()),\n",
    "            ('labencode', MultiColumnLabelEncoder()),\n",
    "        ])),\n",
    "        ('numerics', Pipeline([\n",
    "            ('extract', ColumnExtractor(NUM_FEATS)),\n",
    "            ('fill_with_mean', DFImputer(strategy='mean'))\n",
    "#             ('log', Log1pTransformer())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('scale', DFStandardScaler()),\n",
    "    ('gb', GradientBoostingClassifier())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', DFFeatureUnion(transformer_list=[('categoricals', Pipeline(memory=None,\n",
       "     steps=[('extract', ColumnExtractor(cols=[':degree_level_sought'])), ('dummy', DummyTransformer())])), ('multi_labels', Pipeline(memory=None,\n",
       "     steps=[('extract', ColumnExtractor(cols=['mobile_device_t...      presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False))])"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gb_pipeline.predict_proba(X_val)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6103364132869927"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr_val, tpr_val, thresholds_val = roc_curve(y_val, y_pred)\n",
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline with Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing with a Pipeline\n",
    "gd_pipeline = Pipeline([\n",
    "    ('features', DFFeatureUnion([\n",
    "#         ('dates', Pipeline([\n",
    "#             ('extract', ColumnExtractor(DATE_FEATS)),\n",
    "#             ('to_date', DateFormatter()),\n",
    "#             ('diffs', DateDiffer()),\n",
    "#             ('mid_fill', DFImputer(strategy='median'))\n",
    "#         ])),\n",
    "        ('categoricals', Pipeline([\n",
    "            ('extract', ColumnExtractor(DUMMY_FEATS)),\n",
    "            ('dummy', DummyTransformer())\n",
    "        ])),\n",
    "        ('multi_labels', Pipeline([\n",
    "            ('extract', ColumnExtractor(LABELENCODER_FEATS)),\n",
    "            ('transform_to_string', StringTransformer()),\n",
    "            ('labencode', MultiColumnLabelEncoder()),\n",
    "        ])),\n",
    "        ('numerics', Pipeline([\n",
    "            ('extract', ColumnExtractor(NUM_FEATS)),\n",
    "            ('fill_with_mean', DFImputer(strategy='mean'))\n",
    "#             ('log', Log1pTransformer())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('scale', DFStandardScaler()),\n",
    "    ('gd', GradientBoostingClassifier())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'pca__n_components': [5, 20, 30, 40, 50, 64],\n",
    "#     'logistic__alpha': np.logspace(-4, 4, 5),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": [0.1, 0.2],\n",
    "    \"min_samples_split\": np.linspace(0.1, 0.5),\n",
    "    \"min_samples_leaf\": np.linspace(0.1, 0.5),\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "    \"subsample\":[0.5, 1.0],\n",
    "    \"n_estimators\":[10]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = GridSearchCV(gd_pipeline, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cv.best_score_)    \n",
    "# print(cv.best_params_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter criterion for estimator Pipeline(memory=None,\n     steps=[('features', DFFeatureUnion(transformer_list=[('categoricals', Pipeline(memory=None,\n     steps=[('extract', ColumnExtractor(cols=[':degree_level_sought'])), ('dummy', DummyTransformer())])), ('multi_labels', Pipeline(memory=None,\n     steps=[('extract', ColumnExtractor(cols=['mobile_device_t...      presort='auto', random_state=None, subsample=1.0, verbose=0,\n              warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-492-ea31fe3eeaeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0mtrain_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \"\"\"\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'steps'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m_set_params\u001b[0;34m(self, attr, **params)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_replace_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# 3. Step parameters and other initilisation arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_BaseComposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    272\u001b[0m                                  \u001b[0;34m'Check the list of available parameters '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                                  \u001b[0;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m                                  (key, self))\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdelim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter criterion for estimator Pipeline(memory=None,\n     steps=[('features', DFFeatureUnion(transformer_list=[('categoricals', Pipeline(memory=None,\n     steps=[('extract', ColumnExtractor(cols=[':degree_level_sought'])), ('dummy', DummyTransformer())])), ('multi_labels', Pipeline(memory=None,\n     steps=[('extract', ColumnExtractor(cols=['mobile_device_t...      presort='auto', random_state=None, subsample=1.0, verbose=0,\n              warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cv.predict_proba(X_val)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_val, tpr_val, thresholds_val = roc_curve(y_val, y_pred)\n",
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
